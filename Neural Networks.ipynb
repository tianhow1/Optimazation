{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Neural Networks\n",
    "\n",
    "A map consisting of **neurons** (a.k.a **nodes**) which are interconnected in layers, such that data flows in only one direction. Neural networks are used to approximate complicated functions given their input and output.\n",
    "\n",
    "You set up a model with weights $\\mathbf{w}$ and seek to find\n",
    "$$ \\text{argmin} \\; E(\\mathbf{w})$$\n",
    "where $E$ measures the error of your model, known as the **loss function**.\n",
    "\n",
    "## Neural Network with no Hidden Layers\n",
    "\n",
    "![Perceptron](https://i.imgur.com/RHfrnA1.png)\n",
    "\n",
    "In this 2-layer neural network, you input $x_1,x_2,\\dots x_n$ and your output is $f(w_0 + x_1 w_1 + x_2 w_2 + \\dots + x_n w_n)$, where $f$ is your **activation function**.\n",
    "\n",
    "This 1-layer neural network has an **input layer**, taking in the parameters $x_1,\\dots x_n$.\n",
    "\n",
    "It has an **output layer** $y$.\n",
    "\n",
    "In the above example, $f$ is the **step function**:\n",
    "\n",
    "$$ f(x) = \\begin{cases}\n",
    "1 && \\text{ if } w_0 + x_1 w_1 + \\dots + x_n w_n \\ge 0\\\\\n",
    "0 && \\text{ else }\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "A feedforward neural network consists of multiple layers of 1-layer neural networks.\n",
    "\n",
    "$w_0$ is usually referred to as the **bias** $b$.\n",
    "\n",
    "### Relation to Least Squares Regression\n",
    "\n",
    "If $f(x) = x$, then the model is $y = w_0 + x_1 w_1 + x_2 w_2 + \\dots + x_n w_n$. This is just a linear model: let $A = \\begin{bmatrix}\n",
    "1 & x_{11} & x_{12} \\dots & x_{1n} \\\\\n",
    "\\vdots \\\\\n",
    "1 & x_{m1} & x_{m2} \\dots & x_{mn}\n",
    "\\end{bmatrix}$ and multiply it with $\\begin{bmatrix}\n",
    "w_0 \\\\\n",
    "w_1 \\\\\n",
    "\\vdots \\\\\n",
    "w_n\n",
    "\\end{bmatrix}$\n",
    "\n",
    "for inputs $(x_{i1}, \\dots x_{in})$ for $1 \\le i \\le m$.\n",
    "\n",
    "If $f(x)$ is a different activation function, it's not quite a linear model, but the resemblance is there.\n",
    "\n",
    "## Multi-Layer Neural Network\n",
    "\n",
    "If you have multiple layers, then you take the output of a neuron and use that as input in the next neuron.\n",
    "\n",
    "![NeuralNet](https://i.imgur.com/QU8ilo9.png)\n",
    "\n",
    "**Input Layer**: Holds your input data. Here with 3 nodes in the input layer, we would have 3 features in our input. Consists of three **neurons (nodes)**, labeled $x_1, x_2, x_3$ on the graph.\n",
    "\n",
    "**Output Layer**: Holds the output of the neural network. Consists of two **neurons (nodes)**, labeled $y_1, y_2$.\n",
    "\n",
    "**Hidden Layers**: Intermediate layers in the network. The 1st hidden layer has 2 nodes, the 2nd hidden layer also has 2 nodes.\n",
    "\n",
    "## Backpropagation\n",
    "\n",
    "**The goal**: Find the weights $\\mathbf{w}$ so to minimize the loss function.\n",
    "\n",
    "**How to find these weights?** At every step of training, we can propagate forward to calculate the output of the neural network, then use gradient descent to update the weights.\n",
    "\n",
    "### Example:\n",
    "\n",
    "Consider $E(\\mathbf{w}) = \\frac{1}{2} \\sum_{s=1}^m (y_{ds} - y_s)^2$\n",
    "\n",
    "Where $y_{ds}$ is the desired output, and $y_s$ is the output of the model, with $1 \\le s \\le m$ ($m$ number of outputs). You can expand $y_s$. In a 3-layer neural network:\n",
    "\n",
    "$$ E(\\mathbf{w}) = \\sum_{p=1}^m \\left( y_{dp} - f_p^o \\left( \\sum_{q=1}^l w_{pq}^o z_q\\right)\\right)^2$$\n",
    "\n",
    "where $z_q = f_q^h\\left(\\sum_{i=1}^n w_{qi}^h x_{di}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y_{ds}$ is the desired/actual y\n",
    "\n",
    "$y_s$ is the output from the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
