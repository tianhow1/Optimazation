{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a66c39c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm, solve, multi_dot\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35871741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the function\n",
    "g = lambda x,y: (x-1)**2 + (2*y-1)**2\n",
    "# define derivatives of f to make the gradient\n",
    "Dg = lambda x,y: np.array([2*(x-1), 4*(2*y-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d917300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial x=(4, 1)\n",
      "After 59 iterations, approximate minimum is 1.0978887356815322e-17 at [1.  0.5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5815603231354938"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = (4,1)       # initial point\n",
    "path = [x]\n",
    "print(f'Initial x={x}')\n",
    "dx = np.array([np.inf,np.inf]) # initial large gradient so while loop runs\n",
    "tol = 1e-8          # stop when gradient is smaller than this amount\n",
    "max_steps = 1000      # Maximum number of steps to run the iteration       \n",
    "i=0                   # iteration countz\n",
    "while np.linalg.norm(dx)>tol and i<max_steps:\n",
    "    dx = Dg(x[0],x[1])\n",
    "    \n",
    "    # choose a2=1/5\n",
    "    a = 1.425\n",
    "\n",
    "    # new value of x\n",
    "    xnew = x - a*dx\n",
    "    path.append(xnew)\n",
    "    \n",
    "    # update old value\n",
    "    x = xnew\n",
    "    # update iteration count\n",
    "    i += 1\n",
    "\n",
    "path=np.array(path)\n",
    "print(f'After {i} iterations, approximate minimum is {g(x[0],x[1])} at {x}')\n",
    "xnew = x - a*dx\n",
    "con=(np.linalg.norm(xnew-(1,0.5)))/(np.linalg.norm(x-(1,0.5))) \n",
    "con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6b311b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Rosenbrock, its gradient and Hessian\n",
    "def RBObjFunc(x):\n",
    "    return 100 * (x[1] - x[0]**2)**2 + (1 - x[0])**2\n",
    "def RBGradObjFunc(x):\n",
    "    return np.array([\n",
    "        -400 * x[0] * (x[1] - x[0] ** 2) - 2 * (1 - x[0]),\n",
    "        200 * (x[1] - x[0]**2)      \n",
    "    ])\n",
    "def RBHessianFunc(x):\n",
    "    return np.matrix([\n",
    "        [-400*(x[1] - 3*x[0]**2) + 2, -400 * x[0]], [-400 * x[0], \n",
    "200]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "203f1abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WolfeI(alpha,f,x,dx,p,c1=0.1):\n",
    "    '''Return True/False if Wolfe condition I is satisfied for the given alpha'''\n",
    "    LHS = f(x[0]+alpha*p[0], x[1]+alpha*p[1])\n",
    "    RHS = f(x[0],x[1])+c1*alpha*np.dot(dx(x[0],x[1]),p)\n",
    "    return LHS <= RHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9d3899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method(objFunc, gradObjFunc, hessianFunc, x0, \n",
    "tol, maxIter):                      \n",
    "    path      = [x0]\n",
    "    k         = 0\n",
    "    xk        = x0    \n",
    "    pk        = -np.linalg.solve(hessianFunc(xk[0],xk[1]), gradObjFunc(xk[0],xk[1]))        \n",
    "    while norm(gradObjFunc(xk[0],xk[1])) > tol and k <= maxIter:  \n",
    "        # backtracking\n",
    "       \n",
    "        alpha = 1\n",
    "        while not WolfeI(alpha,objFunc,xk,gradObjFunc,pk) and alpha>1e-5:  # lower limit to prevent small steps, similar to Wolfe II\n",
    "            alpha *= rho   \n",
    "        \n",
    "\n",
    "        xk  = xk + alpha*pk\n",
    "        \n",
    "        pk  = -np.linalg.solve(hessianFunc(xk[0],xk[1])  , gradObjFunc(xk[0],xk[1]))\n",
    "        k   = k + 1\n",
    "        print(\"At {iter} iterations, the step length is {aa}.\".format(iter=k, aa=alpha))\n",
    "        path.append(xk)\n",
    "        \n",
    "    path = np.array(path) # convert to array\n",
    "        \n",
    "    if norm(pk) <= tol:\n",
    "        print(\"Found the minimizer at {x} with {iter} iterations successfully, gradient's norm is {nrm}.\".format(x=xk,iter=k,nrm=norm(pk)))\n",
    "    else:\n",
    "        print(\"Unable to locate minimizer within maximum iterations, last position is at {x}, gradient's norm is {nrm}\".format(x=xk,nrm=norm(pk)))\n",
    "        \n",
    "    return xk, k, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1146e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Rosenbrock, its gradient and Hessian\n",
    "RBObjFunc= lambda x,y: 100 * (y - x**2)**2 + (1 - x)**2\n",
    "RBGradObjFunc=lambda x,y: np.array([\n",
    "        -400 * x * (y - x ** 2) - 2 * (1 - x),\n",
    "        200 * (y - x**2)      \n",
    "    ])\n",
    "RBHessianFunc=lambda x,y: np.matrix([\n",
    "        [-400*(y - 3*x**2) + 2, -400 * x], [-400 * x, 200]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d046c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize, input parameters\n",
    "x0      = np.array([1.2, 1.2]) \n",
    "tol     = 1e-8 \n",
    "maxIter = 1e6\n",
    "rho=0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1289f693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 1 iterations, the step length is 1.\n",
      "At 2 iterations, the step length is 0.5625.\n",
      "At 3 iterations, the step length is 1.\n",
      "At 4 iterations, the step length is 1.\n",
      "At 5 iterations, the step length is 1.\n",
      "At 6 iterations, the step length is 1.\n",
      "At 7 iterations, the step length is 1.\n",
      "At 8 iterations, the step length is 1.\n",
      "Found the minimizer at [1. 1.] with 8 iterations successfully, gradient's norm is 4.965068306494916e-16.\n"
     ]
    }
   ],
   "source": [
    "##Run\n",
    "x_2, iter_2, path_2 = newton_method(RBObjFunc, RBGradObjFunc, RBHessianFunc, x0, tol, maxIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c64f66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_line_search_quasi_newton(update_method, x0, H0,tol):\n",
    "    k = 0\n",
    "    xcoords = [x0[0]]\n",
    "    ycoords = [x0[1]]\n",
    "    path = [[x0[0],x0[1]]]\n",
    "    x_k = x0 \n",
    "    H_k = H0 \n",
    "    g_k = grad_objective_func(x_k)\n",
    "    while norm(g_k) > tol:\n",
    "        p_k = -np.matmul(H_k, g_k)                # search direction\n",
    "   \n",
    "        def subproblem1D(alpha):                  # exact line search\n",
    "            return objective_func(x_k + alpha * p_k)\n",
    "        \n",
    "        res = minimize_scalar(subproblem1D)\n",
    "        alpha_k = res.x      \n",
    "        s_k     = alpha_k * p_k                   # s_k = x_{k+1} - x_k \n",
    "        g_k1    = grad_objective_func(x_k + s_k)  # gk1 is g_{k+1}\n",
    "        y_k     = g_k1 - g_k                      # y_k = g_{k+1} - g_(k)\n",
    "        \n",
    "        k = k + 1                                 # increment\n",
    "        H_k = update_method(H_k, s_k, y_k).A      # .A transforms       \n",
    "#matrix  to ndarray \n",
    "        x_k = x_k + s_k \n",
    "        g_k = g_k1\n",
    "        path.append([x_k[0],x_k[1]])\n",
    "        xcoords.append(x_k[0])\n",
    "        ycoords.append(x_k[1])\n",
    "        \n",
    "    return x_k, k, norm(g_k), xcoords, ycoords ,path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e696de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFP(H, s_k, y_k):\n",
    "    rho = 1.0 / np.dot(s_k, y_k)\n",
    "    vec = H*np.matrix(y_k).T\n",
    "    denom2 = np.matrix(y_k)*vec \n",
    "    H = H + rho*(np.matrix(s_k).T * np.matrix(s_k)) - np.matrix(vec)*np.matrix(vec).T/denom2 # np.outer(vec, vec) = vec * vec^T #H^T=H\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43143e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFGS(H, s_k, y_k): \n",
    "    rho = 1.0 / np.dot(s_k, y_k)\n",
    "    I = np.eye(len(s_k))\n",
    "    A = I - rho * (np.matrix(s_k).T * np.matrix(y_k) )\n",
    "    B = np.matrix(s_k).T * np.matrix(s_k) * rho\n",
    "    H = A * H * A.T + B \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b083f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SR1(H, s_k, y_k):\n",
    "    z = s_k - np.dot(H, y_k)     # the numerator is a matrix\n",
    "    numer = np.matrix(z).T * np.matrix(z)\n",
    "    denom = np.dot(z, y_k)\n",
    "    # skip when the denominator is too small\n",
    "    if np.abs(denom) < 10**(-8) * norm(z) * norm(y_k):\n",
    "        return H\n",
    "    else:\n",
    "        return H + numer/denom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da5f9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(x):\n",
    "    \n",
    "     return 100 * (x[1] - x[0]**2)**2 + (1 - x[0])**2\n",
    "def grad_objective_func(x):\n",
    "    \n",
    "         return np.array([\n",
    "        -400 * x[0] * (x[1] - x[0] ** 2) - 2 * (1 - x[0]),\n",
    "        200 * (x[1] - x[0]**2)      \n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f17a23f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([1.2, 1.2])\n",
    "H0 = np.eye(2)\n",
    "xB, iter_numberB, errB, xcoordsB, ycoordsB,pathB  = exact_line_search_quasi_newton(BFGS, x0, H0,tol = 1e-8)\n",
    "xS, iter_numberS, errS, xcoordsS, ycoordsS,pathS = exact_line_search_quasi_newton(SR1, x0, H0,tol = 1e-8)\n",
    "xD, iter_numberD, errD, xcoordsD, ycoordsD,pathD = exact_line_search_quasi_newton(DFP, x0, H0,tol = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7ee3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_convergence_rate(xcoords,ycoords, minimizer):\n",
    "    '''Given a path defined by an iteration and a known minimizer, approximates convergence rate'''\n",
    "    p=np.log(np.linalg.norm(np.array(xcoords[-1],ycoords[-1])-minimizer\n",
    "                           )/(np.linalg.norm(np.array(xcoords[-2],ycoords[-2])-minimizer))\n",
    "            )/(np.log(np.linalg.norm(np.array(xcoords[-2],ycoords[-2])-minimizer\n",
    "    )/(np.linalg.norm(np.array(xcoords[-3],ycoords[-3])-minimizer))))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f681b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_convergence_rate1(xcoords,ycoords):\n",
    "    '''Given a path defined by an iteration and a known minimizer, approximates convergence rate'''\n",
    "    p=np.log(np.linalg.norm(np.array(xcoords[-1],ycoords[-1])-np.array(xcoords[-2],ycoords[-2])\n",
    "                           )/(np.linalg.norm(np.array(xcoords[-2],ycoords[-2])-np.array(xcoords[-3],ycoords[-3])))\n",
    "            )/(np.log(np.linalg.norm(np.array(xcoords[-2],ycoords[-2])-np.array(xcoords[-3],ycoords[-3])\n",
    "                                     )/(np.linalg.norm(np.array(xcoords[-3],ycoords[-3])\n",
    "                                                       -np.array(xcoords[-4],ycoords[-4])))))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb607968",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "approx_convergence_rate1() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-8761ba6deb4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapprox_convergence_rate1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxcoordsB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mycoordsB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: approx_convergence_rate1() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "pB=approx_convergence_rate1(xcoordsB,ycoordsB,(1,1))\n",
    "pB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "227f56b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "approx_convergence_rate1() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-8ae82921cb23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapprox_convergence_rate1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxcoordsS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mycoordsS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: approx_convergence_rate1() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "pS=approx_convergence_rate1(xcoordsS,ycoordsS,(1,1))\n",
    "pB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a345465f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "approx_convergence_rate1() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d75228817ebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapprox_convergence_rate1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxcoordsS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mycoordsS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: approx_convergence_rate1() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "pS=approx_convergence_rate1(xcoordsS,ycoordsS,(1,1))\n",
    "pS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ce27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_convergence_rate(path, minimizer, numToAvg=3 showPlot=True):\n",
    "    '''Given a path defined by an iteration and a known minimizer, approximates convergence rate'''\n",
    "    err = np.linalg.norm(path-np.array(minimizer),axis=1) # ||x_k-x*||=e_k\n",
    "    \n",
    "    # if converged in very few steps, return infinite order\n",
    "    if len(err)<=3:\n",
    "        return np.inf\n",
    "    \n",
    "    pp = np.zeros(len(err)-3)\n",
    "    for i in range(len(err)-3):\n",
    "        pp[i] = np.log(err[i+2]/err[i+1])/np.log(err[i+1]/err[i])\n",
    "    \n",
    "    if numToAvg>len(pp):\n",
    "        # if not enough iterations to average, just average all\n",
    "        p=np.mean(pp)\n",
    "    else:\n",
    "        # return mean of last few iterations\n",
    "        p=np.mean(pp[-numToAvg:])\n",
    "        \n",
    "    # plot\n",
    "    if showPlot:\n",
    "        plt.plot(pp)\n",
    "        plt.plot(pp*0+p)\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('p')\n",
    "        plt.title(f'p={p}')\n",
    "        plt.show()\n",
    "        \n",
    "    return p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
